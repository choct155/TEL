{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Colorado - Exploration of County Fisc (1979-2009)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have explored the county data in a non-spatial manner (see CO_muni_county), and analyzed single year (2010 Census [Summary File 1](http://www.census.gov/2010census/news/press-kits/summary-file-1.html)) data by Census tract.  We are now going to evaluate the fiscal data provided by the Colorado [Division of Local Government](http://www.colorado.gov/cs/Satellite/DOLA-Main/CBON/1251590375285) from a spatial standpoint.  This script will both examine the panel dynamics of this data set, and also dive into spatial econometric analysis of the data.  For the latter, we will start with spatial lag and error models."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Read-in and Munging"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "from pandas import Series, DataFrame\n",
      "import pandas.io.data as web\n",
      "from IPython.display import HTML\n",
      "\n",
      "#Enable R capability\n",
      "%load_ext rmagic\n",
      "\n",
      "\n",
      "#Set print widith\n",
      "pd.set_option('line_width',140)\n",
      "\n",
      "#Set plot style\n",
      "pd.options.display.mpl_style='default'\n",
      "\n",
      "#Establish working directory\n",
      "workdir='/home/choct155/Google Drive/Dissertation/Data/'\n",
      "\n",
      "#Read in data\n",
      "#county_ent=pd.read_csv(workdir+'COUNTY_ENT_1975_TO_2009.csv')\n",
      "county_gg=pd.read_csv(workdir+'COUNTY_GG_1975_TO_2009.csv')\n",
      "#muni_ent=pd.read_csv(workdir+'MUNY_ENT_1975_to_2009.csv')\n",
      "#muni_gg=pd.read_csv(workdir+'MUNY_GG_1975_to_2009.csv')\n",
      "print county_gg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 2240 entries, 0 to 2239\n",
        "Data columns (total 58 columns):\n",
        "LG_ID                           2240  non-null values\n",
        "NAME                            2240  non-null values\n",
        "LGTYPE_ID                       2240  non-null values\n",
        "AUDIT_YEAR                      2240  non-null values\n",
        "REV_TOTAL                       2240  non-null values\n",
        "REV_TOTAL_TAX                   2240  non-null values\n",
        "REV_PROPERTY_TAX                2240  non-null values\n",
        "REV_SO_TAX                      2240  non-null values\n",
        "REV_SALES_USE_TAX               2240  non-null values\n",
        "REV_OCCUPATION_TAX              2240  non-null values\n",
        "REV_FRANCHISE_TAX               2240  non-null values\n",
        "REV_OTHER_TAX                   2240  non-null values\n",
        "REV_LODGING_TAX                 2240  non-null values\n",
        "REV_REAL_ESTATE_TRANSFER_TAX    2240  non-null values\n",
        "REV_UNCLASS_TAX                 2240  non-null values\n",
        "REV_LICENSES                    2240  non-null values\n",
        "REV_CHARGES                     2240  non-null values\n",
        "REV_FINES                       2240  non-null values\n",
        "REV_TRANSFER_IN                 2240  non-null values\n",
        "REV_INTGOVT                     2240  non-null values\n",
        "REV_HUT                         2240  non-null values\n",
        "REV_CIGARETTE_TAX               2240  non-null values\n",
        "REV_MOTOR_VEH_FEE               2240  non-null values\n",
        "REV_CTF                         2240  non-null values\n",
        "REV_SOCIAL_SERVICE              2240  non-null values\n",
        "ALL_OTHER_INTGOVT               2240  non-null values\n",
        "REV_MISC                        2240  non-null values\n",
        "REV_INTEREST                    2240  non-null values\n",
        "EXP_TOTAL                       2240  non-null values\n",
        "EXP_TOTAL_OPERATING             2240  non-null values\n",
        "EXP_GEN_GOVT                    2240  non-null values\n",
        "EXP_JUDICIAL                    2240  non-null values\n",
        "EXP_TOTAL_PUBLIC_SAFETY         2240  non-null values\n",
        "EXP_POLICE                      2240  non-null values\n",
        "EXP_FIRE                        2240  non-null values\n",
        "EXP_OTHER_PUBLIC_SAFETY         2240  non-null values\n",
        "EXP_TOTAL_PUBLIC_WORKS          2240  non-null values\n",
        "EXP_STREET                      2240  non-null values\n",
        "EXP_TRASH                       2240  non-null values\n",
        "EXP_OTHER_PUBLIC_WORKS          2240  non-null values\n",
        "EXP_HEALTH                      2240  non-null values\n",
        "EXP_RECREATION                  2240  non-null values\n",
        "EXP_SOCIAL_SERVICE              2240  non-null values\n",
        "EXP_MISC                        2240  non-null values\n",
        "EXP_TRANSFER_OUT                2240  non-null values\n",
        "EXP_CAPITAL_OUTLAY              2240  non-null values\n",
        "EXP_DEBT_SERVICE_GEN            2240  non-null values\n",
        "EXP_PRINCIPAL_GEN               2240  non-null values\n",
        "EXP_INTEREST_GEN                2240  non-null values\n",
        "GO_DEBT_GEN                     2240  non-null values\n",
        "REVENUE_DEBT_GEN                2240  non-null values\n",
        "OTHER_DEBT_GEN                  2240  non-null values\n",
        "ASSETS                          2240  non-null values\n",
        "LIABILITIES                     2240  non-null values\n",
        "POPULATION                      2240  non-null values\n",
        "RETAIL_SALES                    2240  non-null values\n",
        "ST_SALES_TAX_PAID               2240  non-null values\n",
        "SALES_TAX_RATE                  2240  non-null values\n",
        "dtypes: float64(1), int64(56), object(1)\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I have previously explored the data structure of this file (CO_muni_county), so I can skip the exploration and just take what I need.  For starters, I need to hierarchically structure the data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Construct hierarchical dictionaries    \n",
      "c_rev_dict={'REV_TOTAL':['REV_TOTAL_TAX','REV_LICENSES','REV_INTGOVT','REV_CHARGES','REV_FINES','REV_MISC','REV_TRANSFER_IN'],\n",
      "          'REV_TOTAL_TAX':['REV_PROPERTY_TAX','REV_SO_TAX','REV_SALES_USE_TAX','REV_FRANCHISE_TAX','REV_OCCUPATION_TAX','REV_OTHER_TAX','REV_UNCLASS_TAX'],\n",
      "          'REV_INTGOVT':['REV_HUT','REV_CIGARETTE_TAX','REV_MOTOR_VEH_FEE','REV_CTF','REV_SOCIAL_SERVICE','ALL_OTHER_INTGOVT']}\n",
      "c_exp_dict={'EXP_TOTAL':['EXP_TOTAL_OPERATING','EXP_TRANSFER_OUT','EXP_CAPITAL_OUTLAY','EXP_DEBT_SERVICE_GEN'],\n",
      "          'EXP_TOTAL_OPERATING':['EXP_GEN_GOVT','EXP_JUDICIAL','EXP_TOTAL_PUBLIC_SAFETY','EXP_TOTAL_PUBLIC_WORKS','EXP_HEALTH','EXP_RECREATION','EXP_SOCIAL_SERVICE','EXP_MISC'],\n",
      "          'EXP_TOTAL_PUBLIC_SAFETY':['EXP_POLICE','EXP_FIRE','EXP_OTHER_PUBLIC_SAFETY'],\n",
      "          'EXP_TOTAL_PUBLIC_WORKS':['EXP_STREET','EXP_TRASH','EXP_OTHER_PUBLIC_WORKS'],\n",
      "          'EXP_DEBT_SERVICE_GEN':['EXP_PRINCIPAL_GEN','EXP_INTEREST_GEN']}\n",
      "c_debt_dict={'TOTAL_DEBT':['GO_DEBT_GEN','REVENUE_DEBT_GEN','OTHER_DEBT_GEN']}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We also need to deflate our data.  The deflator information comes from the [FRED database](http://research.stlouisfed.org/fred2/)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Open feed to CPI info\n",
      "cpi=web.get_data_fred('USACPIBLS','1/1/1975','1/1/2009')\n",
      "\n",
      "#Create copy in case offline work is occurring\n",
      "cpi.to_csv(workdir+'us_cpi_1975_2009.csv')\n",
      "\n",
      "#Create common index for later join with data\n",
      "cpi['AUDIT_YEAR']=range(1975,2010)\n",
      "cpi2=cpi.reset_index().set_index('AUDIT_YEAR')\n",
      "\n",
      "#Rename columns\n",
      "cpi2.columns=['DATE','CPI']\n",
      "\n",
      "#Drop DATE\n",
      "cpi2.pop('DATE')\n",
      "\n",
      "#Calculate deflator ratios\n",
      "dfl=cpi2.div(cpi2.ix[2009])\n",
      "\n",
      "dfl.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>CPI</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AUDIT_YEAR</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>1975</th>\n",
        "      <td> 0.250816</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1976</th>\n",
        "      <td> 0.265268</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1977</th>\n",
        "      <td> 0.282517</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1978</th>\n",
        "      <td> 0.303963</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1979</th>\n",
        "      <td> 0.338462</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "                 CPI\n",
        "AUDIT_YEAR          \n",
        "1975        0.250816\n",
        "1976        0.265268\n",
        "1977        0.282517\n",
        "1978        0.303963\n",
        "1979        0.338462"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we need to set the index and actually deflate the data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Set index\n",
      "c_gg=county_gg.set_index(['NAME','AUDIT_YEAR','LGTYPE_ID'])\n",
      "\n",
      "#Implicit merge\n",
      "c_gg['DFL']=dfl.ix[c_gg.index.get_level_values(level='AUDIT_YEAR')].values\n",
      "\n",
      "#Divide each column by deflator ratio\n",
      "cgg_real=c_gg.div(c_gg['DFL'],axis=0)\n",
      "\n",
      "#Replace population and ID variables\n",
      "cgg_real['CTY_POP']=c_gg['POPULATION']\n",
      "cgg_real['LGID']=c_gg['LG_ID']\n",
      "\n",
      "cgg_real[['LG_ID','REV_TOTAL','POPULATION','CTY_POP','LGID']].head()\n",
      "\n",
      "cgg_real.to_csv(workdir+'CO_cty_fin.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th>LG_ID</th>\n",
        "      <th>REV_TOTAL</th>\n",
        "      <th>POPULATION</th>\n",
        "      <th>CTY_POP</th>\n",
        "      <th>LGID</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>NAME</th>\n",
        "      <th>AUDIT_YEAR</th>\n",
        "      <th>LGTYPE_ID</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th rowspan=\"5\" valign=\"top\">Adams County</th>\n",
        "      <th>1975</th>\n",
        "      <th>1</th>\n",
        "      <td> 3990.975836</td>\n",
        "      <td> 1.101322e+08</td>\n",
        "      <td> 864698.141264</td>\n",
        "      <td> 216880</td>\n",
        "      <td> 1001</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1976</th>\n",
        "      <th>1</th>\n",
        "      <td> 3773.541301</td>\n",
        "      <td> 1.235622e+08</td>\n",
        "      <td> 839675.140598</td>\n",
        "      <td> 222739</td>\n",
        "      <td> 1001</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1977</th>\n",
        "      <th>1</th>\n",
        "      <td> 3543.143564</td>\n",
        "      <td> 1.249685e+08</td>\n",
        "      <td> 800428.341584</td>\n",
        "      <td> 226135</td>\n",
        "      <td> 1001</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1978</th>\n",
        "      <th>1</th>\n",
        "      <td> 3293.167178</td>\n",
        "      <td> 1.441683e+08</td>\n",
        "      <td> 788366.457055</td>\n",
        "      <td> 239634</td>\n",
        "      <td> 1001</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1979</th>\n",
        "      <th>1</th>\n",
        "      <td> 2957.500000</td>\n",
        "      <td> 1.306004e+08</td>\n",
        "      <td> 727004.318182</td>\n",
        "      <td> 246063</td>\n",
        "      <td> 1001</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "                                         LG_ID     REV_TOTAL     POPULATION  CTY_POP  LGID\n",
        "NAME         AUDIT_YEAR LGTYPE_ID                                                         \n",
        "Adams County 1975       1          3990.975836  1.101322e+08  864698.141264   216880  1001\n",
        "             1976       1          3773.541301  1.235622e+08  839675.140598   222739  1001\n",
        "             1977       1          3543.143564  1.249685e+08  800428.341584   226135  1001\n",
        "             1978       1          3293.167178  1.441683e+08  788366.457055   239634  1001\n",
        "             1979       1          2957.500000  1.306004e+08  727004.318182   246063  1001"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Integrate Spatial Information"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To map the data and perform spatial analyses, we need to couple these fiscal data with locational information from a shapefile provided by the [Census FTP site](ftp://ftp2.census.gov/geo/tiger/TIGER2012/).  County-level polygons are sufficiently large that they, unlike Census tracts, are provided in one nationwide file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "#install.packages(\"rgdal\")\n",
      "library(maptools)\n",
      "library(gpclib)\n",
      "library(sp)\n",
      "library(ggmap)\n",
      "#library(rgdal)\n",
      "library(raster)\n",
      "library(ggplot2)\n",
      "library(plyr)\n",
      "\n",
      "#Read in Ward shapefile\n",
      "us<-readShapeSpatial('/home/choct155/Google Drive/Dissertation/Data/spatial/US/tl_2012_us_county.shp')\n",
      "projection(us) <- '+proj=longlat +datum=NAD83'\n",
      "print(summary(us))\n",
      "cat('\\n')\n",
      "print(head(us))\n",
      "cat('\\n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in dev.off() : cannot shut down device 1 (the null device)\n",
        "In addition: Warning messages:\n",
        "1: In png(\"/tmp/tmp6R3FeW/Rplots%03d.png\", ) :\n",
        "  unable to load shared object '/usr/lib/R/library/grDevices/libs//cairo.so':\n",
        "  /usr/lib/x86_64-linux-gnu/libpangocairo-1.0.so.0: undefined symbol: cairo_ft_font_options_substitute\n",
        "2: In png(\"/tmp/tmp6R3FeW/Rplots%03d.png\", ) : failed to load cairo DLL\n"
       ]
      },
      {
       "ename": "RRuntimeError",
       "evalue": "Error in dev.off() : cannot shut down device 1 (the null device)\n",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mRRuntimeError\u001b[0m                             Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-5-0335a780e339>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'R'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu'#install.packages(\"rgdal\")\\nlibrary(maptools)\\nlibrary(gpclib)\\nlibrary(sp)\\nlibrary(ggmap)\\n#library(rgdal)\\nlibrary(raster)\\nlibrary(ggplot2)\\nlibrary(plyr)\\n\\n#Read in Ward shapefile\\nus<-readShapeSpatial(\\'/home/choct155/Google Drive/Dissertation/Data/spatial/US/tl_2012_us_county.shp\\')\\nprojection(us) <- \\'+proj=longlat +datum=NAD83\\'\\nprint(summary(us))\\ncat(\\'\\\\n\\')\\nprint(head(us))\\ncat(\\'\\\\n\\')'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/home/choct155/analysis/Anaconda/lib/python2.7/site-packages/ipython-1.0.0-py2.7.egg/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2121\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2122\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2123\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2124\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/choct155/analysis/Anaconda/lib/python2.7/site-packages/ipython-1.0.0-py2.7.egg/IPython/extensions/rmagic.pyc\u001b[0m in \u001b[0;36mR\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
        "\u001b[1;32m/home/choct155/analysis/Anaconda/lib/python2.7/site-packages/ipython-1.0.0-py2.7.egg/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/choct155/analysis/Anaconda/lib/python2.7/site-packages/ipython-1.0.0-py2.7.egg/IPython/extensions/rmagic.pyc\u001b[0m in \u001b[0;36mR\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m    597\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dev.off()'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m         \u001b[1;31m# read out all the saved .png files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/choct155/analysis/Anaconda/lib/python2.7/site-packages/rpy2/robjects/__init__.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrinterface\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/choct155/analysis/Anaconda/lib/python2.7/site-packages/rpy2/robjects/functions.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr_k\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSignatureTranslatedFunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/home/choct155/analysis/Anaconda/lib/python2.7/site-packages/rpy2/robjects/functions.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mnew_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpy2ri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mri2py\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mRRuntimeError\u001b[0m: Error in dev.off() : cannot shut down device 1 (the null device)\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The shapefile data must be trimmed down to contain only Colorado counties before merging with the fiscal data.  In order to always be able to return to the well, and to avoid writing over objects to ease debugging if need be, we will make a new object to work on.\n",
      "\n",
      "We also need to prepare for merging the data we will be manipulating back in with the spatial information.  To make this happen we must ensure that we have a variable that keeps track of which polygon the data correspond to.  The polygon IDs are housed in the **ID** slot of the **polygon** objects, which in turn sit in the **polygons** slot of the **SpatialPolygonsDataFrame** object (see Spatial_Classes for a breakdown of how this all fits together).  In any event, we will actively use the polygon IDs to create our sorting variable."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "#Create new subset object\n",
      "co<-us[us$STATEFP=='08',]\n",
      "\n",
      "#Verify IDs\n",
      "IDs<-sapply(slot(co,'polygons'),\n",
      "             function(x) slot(x,'ID'))\n",
      "print(IDs)\n",
      "cat('\\n')\n",
      "                 \n",
      "#Create sorting variable by assigning the list populated by polygon IDs\n",
      "co@data$sorting_id<-sapply(slot(co,'polygons'),\n",
      "                          function(x) slot(x,'ID'))\n",
      "\n",
      "#Pull data out of SPDF into standalone object\n",
      "co_df<-as(co,'data.frame')\n",
      "print(str(co_df))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, there is no exact matching variable that can be used to merge the spatial and fiscal data.  Since the data management required is a bit more involved, I am going to pull the spatial data from R into the Python namespace.  Before that happens, however, I need to convert the data types.  Factor types in R will come across in Python as a numeric ordinal value corresponding to the level position that R has assigned (for our purposes, in rather arbitrary fashion).  \n",
      "\n",
      "Variables in the index interval [1:13] must be converted from factor to character, while variables on the index interval [16:17] must be converted from factor to numeric."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "#Convert first 13 variables to character \n",
      "co_df[,1:13] <- sapply(co_df[,1:13], as.character)\n",
      "\n",
      "#Convert INTPTLAT and INTPTLON to numeric\n",
      "co_df[,16:17]<-sapply(co_df[,16:17], function(x) as.numeric(as.character(x)))\n",
      "    \n",
      "print(str(co_df))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data will come across as a numpy ndarray, without columns labels.  Thus, labels will have to be pulled in a second object."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "cols<-colnames(co_df)\n",
      "print(cols)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pulling the data into Python..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%Rpull co_df cols"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Building a usable DataFrame is actually quite easy.  The labels can be zipped to the corresponding arrays, providing the tuple list content that can be converted into a dictionary.  Dictionaries can, of course, be turned into DataFrames."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Generate dictionary containing the spatial data from R\n",
      "co_dict=dict(zip(cols,co_df))\n",
      "\n",
      "#Convert to DataFrame\n",
      "co_DF=DataFrame(co_dict)\n",
      "\n",
      "print co_DF[co_DF.columns[:9]].head().to_string()\n",
      "print co_DF[co_DF.columns[9:]].head().to_string()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can see about merging these data.  First, let's make sure that we have the same counties in there.  To do this, we will first quickly check that the length of unique sets of counties are the same.  Then we will construct a new variable in cgg_real that contains only the 'proper' name element of counties (e.g. 'Adams' for 'Adams County').  This corresponds to the NAME variable in co_DF, allowing us to check equality of sets directly."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'THE NUMBER OF COUNTIES IN co_DF AND cgg_real IS EQUIVALENT:',\\\n",
      "len(set(cgg_real.index.get_level_values(level='NAME')))==len(set(co_DF['NAME']))\n",
      "\n",
      "#Create new variable in cgg_real that includes only the first name of the county\n",
      "cgg_real['FNAME']=''\n",
      "for i in range(len(cgg_real.index)):\n",
      "    cgg_real['FNAME'][i]=cgg_real.index.get_level_values(level='NAME')[i].split()[0].replace(',','')\n",
      "\n",
      "print 'THE SAME COUNTIES ARE REPRESENTED IN BOTH SETS:',set(cgg_real['FNAME'])==set(co_DF['NAME'])\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The sets are not identical, so where we have not achived overlap ([exclusive disjunction](http://en.wikipedia.org/wiki/Exclusive_or)).  We could use a loop to compare each element, but set operations are very fast.  If we don't care about order, we should leverage that fact."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print set(cgg_real['FNAME']).difference(set(co_DF['NAME']))\n",
      "print set(co_DF['NAME']).difference(set(cgg_real['FNAME']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ah, it is clear that our naming convention for cgg_real['FNAME'] was ill conceived.  After some experimentation, I am not sure we can get there with a clean rule.  However, a nested loop testing the presence of a substring as a condition could get the job done.  \n",
      "\n",
      "This is a much slower method.  If we were to simply loop through cgg_real.index, testing each element to see if one member of co_DF['NAME'] was a substring, it would require 2240 X 64 = 143,360 string comparisons.  It's not untenable, but it takes longer than is necessary.  We can cut this down by using the set of the index, and then assigning the correct FNAME value to blocks at a time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Create list of cgg_real counties over which to iterate\n",
      "cgg_cty=list(set(cgg_real.index.get_level_values(level='NAME')))\n",
      "\n",
      "#Loop through cgg_real counties\n",
      "for i in range(len(cgg_cty)):\n",
      "    #For each cgg_real county, loop through co_DF counties\n",
      "    for j in range(len(co_DF['NAME'])):\n",
      "        #Test if co_DF county name is contained within cgg_real county name\n",
      "        if co_DF['NAME'][j] in cgg_cty[i]:\n",
      "            #print co_DF['NAME'][j],'is in',cgg_cty[i]\n",
      "            #If True, assign co_DF county name to all records that contain cgg_real county name\n",
      "            cgg_real['FNAME'][cgg_real.index.get_level_values(level='NAME')==cgg_cty[i]]=co_DF['NAME'][j]\n",
      "        else:\n",
      "            #If not true, do nothing.\n",
      "            pass\n",
      "\n",
      "print cgg_real['FNAME']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looks ok at first glance, let's test again."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'THE SAME COUNTIES ARE REPRESENTED IN BOTH SETS:',set(cgg_real['FNAME'])==set(co_DF['NAME'])\n",
      "print set(cgg_real['FNAME']).difference(set(co_DF['NAME']))\n",
      "print set(co_DF['NAME']).difference(set(cgg_real['FNAME']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Crap.  Let's look at what's happening here."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Identify FNAME for Rio Grande\n",
      "print cgg_real['FNAME'][cgg_real.index.get_level_values(level='NAME')=='Rio Grande County'].head()\n",
      "\n",
      "#Determine coverage of this FNAME\n",
      "print cgg_real['FNAME'][cgg_real['FNAME']=='Grand']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ah, our rule isn't perfect.  Since substring 'Grand' is contained in both 'Grand County' and 'Rio Grande County', we have over-assigned it to an additional county.  Fixing one county is easy enough."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Patch Rio Grande County\n",
      "cgg_real['FNAME'][cgg_real.index.get_level_values(level='NAME')=='Rio Grande County']='Rio Grande'\n",
      "\n",
      "#Retest equality of sets\n",
      "print 'THE SAME COUNTIES ARE REPRESENTED IN BOTH SETS:',set(cgg_real['FNAME'])==set(co_DF['NAME'])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can merge these data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(cgg_real),len(co_DF),len(cgg_real)/len(co_DF)\n",
      "co_county_sp=pd.merge(cgg_real.reset_index(),co_DF,left_on='FNAME',right_on='NAME')\n",
      "co_county_sp.to_csv(workdir+'CO_county_ggfin.csv')\n",
      "\n",
      "print len(set(co_county_sp['sorting_id']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can push back to R to reintegrate the data into the shapefile."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas.rpy.common as com\n",
      "\n",
      "#Convert pandas DataFrames to R data.frames\n",
      "cgg_sp_r=com.convert_to_r_dataframe(co_county_sp.reset_index())\n",
      "\n",
      "#Push new data.frame into the R namespace\n",
      "%Rpush cgg_sp_r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Having merged in the Python namespace, we need only to order the data by sorting_id and check to make sure the row names correspond."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "#Reorder by sorting_id\n",
      "cgg.o<-cgg_sp_r[order(as.numeric(cgg_sp_r$sorting_id)),]\n",
      "\n",
      "#Check equality of objects\n",
      "print(paste('Equality of Row Names (ordered vs. original):',identical(row.names(cgg.o),row.names(co_df))))\n",
      "\n",
      "#Check equality of object lengths\n",
      "print(paste('Equality of Row Name Length (ordered vs. original):',identical(length(row.names(cgg.o)),\n",
      "                                                                            length(row.names(co_df)))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ah, of course they don't.  The county finance data include all years, while the original *data* slot in the SPDF included only a single cross-section.  The unique sorting_id values should match, but the row names will not."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "#Check equality of objects\n",
      "print(paste('Equality of Row Names (ordered vs. original):',identical(unique(cgg.o$sorting_id),row.names(co_df))))\n",
      "\n",
      "#Check equality of object lengths\n",
      "print(paste('Equality of Row Name Length (ordered vs. original):',identical(length(unique(cgg.o$sorting_id)),\n",
      "                                                                            length(row.names(co_df)))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And this is confirmed.  The question is where to go from here... Do I have to create a new shapefile for every year?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "library(rgdal)\n",
      "print(summary(co))\n",
      "\n",
      "#Convert to WGS84\n",
      "co_ll<-spTransform(co,CRS('+proj=longlat +datum=WGS84'))\n",
      "\n",
      "print(summary(co_ll))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print co_county_sp.columns\n",
      "print co_DF.head()\n",
      "co_county_sp.to_csv(workdir+'CO_cty_finsp.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}